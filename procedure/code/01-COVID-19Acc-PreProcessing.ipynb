{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: RP- Spatial Accessibility of COVID-19 Healthcare Resources in Illinois Pre-Processing Script\n",
    "---\n",
    "\n",
    "This is a script that automates as much of the data gathering and pre-processing as possible for reproduction of Kang et al. (2020).\n",
    "\n",
    "**Reproduction of**: Rapidly measuring spatial accessibility of COVID-19 healthcare resources: a case study of Illinois, USA\n",
    "\n",
    "Original study *by* Kang, J. Y., A. Michels, F. Lyu, Shaohua Wang, N. Agbodo, V. L. Freeman, and Shaowen Wang. 2020. Rapidly measuring spatial accessibility of COVID-19 healthcare resources: a case study of Illinois, USA. International Journal of Health Geographics 19 (1):1â€“17. DOI:[10.1186/s12942-020-00229-x](https://ij-healthgeographics.biomedcentral.com/articles/10.1186/s12942-020-00229-x).\n",
    "\n",
    "Script Authors: Derrick Burt and Joseph Holler\n",
    "\n",
    "Reproduction Materials Available at: [RP-Kang Repository](https://github.com/HEGSRR/RPr-Kang-2020)\n",
    "\n",
    "Created: `29 Jun 2021`\n",
    "Revised: `23 Aug 2021`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules\n",
    "Import necessary libraries to run this model.\n",
    "See `requirements.txt` for the library versions used for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import folium\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Directories\n",
    "\n",
    "Because we have restructured the repository for replication, we need to check our working directory and make necessary adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to set work directory properly\n",
    "if os.path.basename(os.getcwd()) == 'code':\n",
    "    os.chdir('../../')\n",
    "    \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Chicago Shapfile and Create Hexagon Grids (500-meter resolution)\n",
    "\n",
    "Could not pre-process this step because there is no clear-cut way to construct hex grids from a .gdf with python.\n",
    "\n",
    "The Chicago 'Place' shapfile can be accessed from:\n",
    "ftp://ftp2.census.gov/geo/tiger//TIGER2020/PLACE/tl_2020_17_place.zip\n",
    "\n",
    "with the following code:\n",
    "\n",
    "```py\n",
    "# Download Illinous plac tract shapefiles to data/raw/public/Pre-Processing/ for All of Illinious (017)\n",
    "if not os.path.exists('data/raw/public/Pre-Processing/tl_2020_17_place.zip'):\n",
    "    !wget -P data/raw/public/Pre-Processing/ ftp://ftp2.census.gov/geo/tiger//TIGER2020/PLACE/tl_2020_17_place.zip\n",
    "    # Extract shapefiles\n",
    "    !unzip -d data/raw/public/Pre-Processing/ data/raw/public/Pre-Processing/tl_2020_17_place.zip\n",
    "    # Read in all place shapefiles for Illinois\n",
    "    place_shp = gpd.read_file('data/raw/public/Pre-Processing/tl_2020_17_place.shp')\n",
    "    # Select only Chicago\n",
    "    chicago_shp = place_shp.loc[place_shp['NAME']=='Chicago']\n",
    "    # Save as shapefile\n",
    "    chicago_shp.to_file('data/raw/public/Pre-Processing/chicago_place.shp')\n",
    "else:\n",
    "    # Read in all census tracts for Illinois\n",
    "    chicago_shp = gpd.read_file('data/raw/public/Pre-Processing/chicago_place.shp')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in and plot grid file for Chicago\n",
    "grid_file = gpd.read_file('./data/raw/public/GridFile/Chicago_Grid.shp')\n",
    "grid_file.plot(figsize=(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hospital Data\n",
    "\n",
    "Note that 999 is treated as a \"NULL\"/\"NA\" so these hospitals are filtered out. This data contains the number of ICU beds and ventilators at each hospital.\n",
    " \n",
    "We could not automate the pre-processing steps for the hospital data because of ambiguous documentation of the sources:\n",
    "\n",
    "The paper lists IDPH as a source for ventilators and icu beds, but the site only makes IDPH data publicly available at the state summary level.\n",
    "\n",
    "We were able to get hospital data from:\n",
    "https://opendata.arcgis.com/datasets/6ac5e325468c4cb9b905f1728d6fbf0f_0.geojson\n",
    "\n",
    "And ICU bed data from:\n",
    "https://healthdata.gov/resource/uqq2-txqb.json\n",
    "\n",
    "With the following code:\n",
    "```py\n",
    "# ADD CODE TO SAFE INTO RAW DATA FOLDER\n",
    "# Set file paths for general care and icu beds\n",
    "fp_gen = 'https://opendata.arcgis.com/datasets/6ac5e325468c4cb9b905f1728d6fbf0f_0.geojson'\n",
    "fp_icu = 'https://healthdata.gov/resource/uqq2-txqb.json'\n",
    "\n",
    "# Eequests for g eneral care and icu beds\n",
    "r_gen = requests.get(fp_gen)\n",
    "r_icu = requests.get(fp_icu)\n",
    "\n",
    "# Get hospitals \n",
    "hospitals_gen = gpd.GeoDataFrame.from_features(geojson.loads(r_gen.content),  crs=\"EPSG:26971\")\n",
    "hospitals_icu = pd.DataFrame.from_dict(json.loads(r_icu.content))\n",
    "\n",
    "# # Filter for icu and general care\n",
    "hospitals_gen = hospitals_gen.loc[(hospitals_gen['STATE'] == 'IL') & (hospitals_gen['TYPE'] == 'GENERAL ACUTE CARE')]\n",
    "# ERROR Here: it is only taking the first thousand\n",
    "hospitals_icu = hospitals_icu[['hospital_pk', 'collection_week', 'state', 'city', 'ccn', 'hospital_name', 'zip', 'ccn', 'address', 'total_icu_beds_7_day_avg']]\n",
    "\n",
    "# Capitalize join column \n",
    "hospitals_icu.rename(columns={'address':'ADDRESS'}, inplace=True)\n",
    "\n",
    "# Join\n",
    "hospitals_api = hospitals_gen.merge(hospitals_icu, on='ADDRESS')\n",
    "\n",
    "# Check \n",
    "hospitals_icu['city'].unique()\n",
    "```\n",
    "\n",
    "But could not incorporate it into the notebook as we could not find ventilator data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in hospital data\n",
    "hospitals = gpd.read_file('./data/raw/public/HospitalData/Chicago_Hospital_Info.shp')\n",
    "hospitals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing: \n",
    "\n",
    "all of the pre-processing steps are provided in the code below. However, the code set up to only grab those files from the source if they do not already exist. All of the pre-processd data in the below steps were gathered and saved to the repository on July 15, 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automate/Pre-Process Census Data  with API\n",
    "\n",
    "*Note* you will need to download a new module called 'censusdata'\n",
    "\n",
    "To do this, open a terminal in the cybergisx environment and type:\n",
    "\n",
    "```pip install censusdata```\n",
    "\n",
    "**Note: we deviate from the original paper's methodology here bringing in a larger buffer distance of census tracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load module\n",
    "import censusdata as cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/raw/public/Pre-Processing/overfifty_tracts_preprocessed.csv\"):\n",
    "    # Read in all Illinois tracts using census API\n",
    "    pop_api = cd.download('acs5', 2018,\n",
    "                                 cd.censusgeo([('state', '17'), ('tract', '*')]),\n",
    "                                     ['B01001_001E', 'B01001_016E', 'B01001_017E', 'B01001_018E', 'B01001_019E', \n",
    "                                      'B01001_020E', 'B01001_021E', 'B01001_022E', 'B01001_023E', 'B01001_024E', \n",
    "                                      'B01001_025E', 'B01001_040E', 'B01001_041E', 'B01001_042E', 'B01001_043E', \n",
    "                                      'B01001_044E', 'B01001_045E', 'B01001_046E', 'B01001_047E', 'B01001_048E',\n",
    "                                      'B01001_049E'])\n",
    "    ## Reformat and Rename columns\n",
    "    # Sum + Rename 50+ population\n",
    "    pop_api['OverFifty'] = pop_api.iloc[:, 1:21].sum(axis=1)\n",
    "\n",
    "    # Rename Total Pop column\n",
    "    pop_api['TotalPop'] = pop_api['B01001_001E']\n",
    "    \n",
    "    # Drop irrelevant columns\n",
    "    pop_api = pop_api.drop(pop_api.columns[0:21], axis=1)\n",
    "    \n",
    "    # Create column from index tract # -- we will need thee tract ID for a join\n",
    "    pop_api['TRACTCE'] = pop_api.index\n",
    "\n",
    "    # Convert to string \n",
    "    pop_api['TRACTCE'] = pop_api['TRACTCE'].astype(str)\n",
    "\n",
    "    # Slice last 6 digits (tract id)\n",
    "    pop_api['TRACTCE'] = pop_api['TRACTCE'].str.slice(-6)\n",
    "\n",
    "    # IF running the first time and path does not exist, uncommnt below to save:\n",
    "    #pop_api.to_csv(\"data/raw/public/Pre-Processing/overfifty_tracts_preprocessed.csv\", sep=',')\n",
    "\n",
    "else:\n",
    "    pop_api = pd.read_csv(\"data/raw/public/Pre-Processing/overfifty_tracts_preprocessed.csv\",\n",
    "                         dtype={'Unnamed:0':str,'OverFifty':np.int64,'TotalPop':np.int64,'TRACTCE':str})\n",
    "\n",
    "pop_api.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zip Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/raw/public/Pre-Processing/population_zip_preprocessed.csv\"):\n",
    "    # Read in all Illinois tracts using census API\n",
    "    zip_api = cd.download('acs5', 2019,\n",
    "                                 cd.censusgeo([('state', '17'), ('zip code tabulation area', '*')]),\n",
    "                                              ['B01003_001E'])\n",
    "    \n",
    "    # rename population column\n",
    "    pop_col = {\"B01003_001E\":\"pop\"}\n",
    "    zip_api = zip_api.rename(columns=pop_col)\n",
    "    \n",
    "    # Create column from index tract # -- we will need thee tract ID for a join\n",
    "    zip_api['ZCTA5CE10'] = zip_api.index\n",
    "    \n",
    "    # Convert to string \n",
    "    zip_api['ZCTA5CE10'] = zip_api['ZCTA5CE10'].astype(str)\n",
    "    \n",
    "    # Slice last 6 digits (tract id)\n",
    "    zip_api['ZCTA5CE10'] = zip_api['ZCTA5CE10'].str.slice(6,11)\n",
    "    \n",
    "    # IF running the first time and path does not exist, uncommnt below to save:\n",
    "    #zip_api.to_csv(\"data/raw/public/Pre-Processing/population_zip_preprocessed.csv\", sep=',')\n",
    "\n",
    "else:\n",
    "    zip_api = pd.read_csv(\"data/raw/public/Pre-Processing/population_zip_preprocessed.csv\",\n",
    "                         dtype={'Unnamed:0':str,'pop':np.int64,'ZCTA5CE10':str})\n",
    "    \n",
    "zip_api.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automate/Pre-Process COVID-19 with Requests\n",
    "\n",
    "Download covid data that will be kjoined to zip code geographies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import geojson\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/raw/public/Pre-Processing/covidcases_zip_preprocessed.csv\"):\n",
    "    # Unfortunately... I have not found how to access archived COVID-119 case data, so this data is cases from 4/6/2021 - 6/30/2021 (or current date...) \n",
    "    # Set file path\n",
    "    fp_covid = 'https://idph.illinois.gov/DPHPublicInformation/api/COVIDExport/GetZip'\n",
    "\n",
    "    # Make reqeuest\n",
    "    r_covid = requests.get(fp_covid)\n",
    "\n",
    "    # Save request as dataframe\n",
    "    covid_cases = pd.DataFrame.from_dict(json.loads(r_covid.content))\n",
    "\n",
    "    # Change confirmed cases to cases\n",
    "    cases_col = {'zip':\"ZCTA5CE10\", \"confirmed_cases\":\"cases\"}\n",
    "    covid_cases = covid_cases.rename(columns=cases_col)\n",
    "    \n",
    "    # Merge covid case data with zip code population to normalize cases\n",
    "    covid_api = covid_cases.merge(zip_api, how=\"inner\", on=\"ZCTA5CE10\")\n",
    "    \n",
    "    # IF running the first time and path does not exist, uncomment below to save:\n",
    "    #covid_api.to_csv(\"data/raw/public/Pre-Processing/covidcases_zip_preprocessed.csv\", sep=',')\n",
    "    \n",
    "else:\n",
    "    covid_api = pd.read_csv(\"data/raw/public/Pre-Processing/covidcases_zip_preprocessed.csv\",\n",
    "                           dtype={'reportdat':str,'ZCTA5CE10':str,'case':np.int64,'total_testd':np.int64,'pop':np.int64})\n",
    "    \n",
    "covid_api.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Census Boundary Shapefiles with FTP Site and Join to Population/Covid Case Data\n",
    "\n",
    "#### Note: Here, we extract *census tracts* and *zip code geographies* based on their spatial relationship (intersection) with the street network\n",
    "\n",
    "Census TIGER/Line shapefiles can bee accessed from ftp://ftp2.census.gov/geo/tiger/ using !wget\n",
    "\n",
    "File path for Cook County 2010 tracts: ftp://ftp2.census.gov/geo/tiger//TIGER2010/TRACT/2010/tl_2010_17031_tract10.zip\n",
    "\n",
    "File path for Illinois 2010 tracts: ftp://ftp2.census.gov/geo/tiger//TIGER2018/TRACT/tl_2018_17_tract.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check directory -- we want to downlaod the raw data directly into our pre-processing data folder\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download census tract shapefiles to data/raw/public/Pre-Processing/ for All of Chicago (017)\n",
    "if not os.path.exists('data/raw/public/Pre-Processing/tl_2018_17_tract.zip'):\n",
    "    !wget -P data/raw/public/Pre-Processing/ ftp://ftp2.census.gov/geo/tiger//TIGER2018/TRACT/tl_2018_17_tract.zip\n",
    "    # Extract shapefiles\n",
    "    !unzip -d data/raw/public/Pre-Processing/ data/raw/public/Pre-Processing/tl_2018_17_tract.zip\n",
    "    # Read in all census tracts for Illinois\n",
    "    tracts_shp = gpd.read_file('data/raw/public/Pre-Processing/tl_2018_17_tract.shp')\n",
    "else:\n",
    "    # Read in all census tracts for Illinois\n",
    "    tracts_shp = gpd.read_file('data/raw/public/Pre-Processing/tl_2018_17_tract.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set crs to WGS 84\n",
    "tracts_shp = tracts_shp.to_crs(epsg=4326)\n",
    "\n",
    "# Select only tracts from Cook countiy + its adjacent counties\n",
    "tracts_shp = tracts_shp.loc[(tracts_shp[\"COUNTYFP\"] == '031') |\n",
    "                            (tracts_shp[\"COUNTYFP\"] == '043') |\n",
    "                            (tracts_shp[\"COUNTYFP\"] == '097') |\n",
    "                            (tracts_shp[\"COUNTYFP\"] == '197') ]\n",
    "\n",
    "# Check crs\n",
    "print(tracts_shp.crs)\n",
    "\n",
    "# Check length\n",
    "print(len(tracts_shp))\n",
    "\n",
    "# Check column names\n",
    "tracts_shp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for join\n",
    "new_names = {\"GEOID10\":\"GEOID\", \"TRACTCE10\":\"TRACTCE\"}\n",
    "tracts_shp = tracts_shp.rename(columns=new_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Tracts shape with Tracts Population data\n",
    "## This drops duplicate values so that we do not end up with\n",
    "atrisk_data = tracts_shp.merge(pop_api.drop_duplicates(subset=['TRACTCE']), how='inner', on=\"TRACTCE\")\n",
    "atrisk_data= atrisk_data.drop(atrisk_data.columns[5:10], axis=1)\n",
    "len(atrisk_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atrisk_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zip codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check directory -- we want to downlaod the raw tract data directly into our data folder\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download zip code shapefiles to data/raw/public/Pre-Processing/ for entire US\n",
    "## I have not yet found a way to select by state before extracting\n",
    "if not os.path.exists('data/raw/public/Pre-Processing/cb_2018_us_zcta510_500k.zip'):\n",
    "    !wget -P data/raw/public/Pre-Processing/ ftp://ftp2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_zcta510_500k.zip\n",
    "    # Extract shapefiles\n",
    "    !unzip -d data/raw/public/Pre-Processing/ data/raw/public/Pre-Processing/cb_2018_us_zcta510_500k.zip\n",
    "    # read in zip code data\n",
    "    usa_zip = gpd.read_file('data/raw/public/Pre-Processing/cb_2018_us_zcta510_500k.shp')\n",
    "else:\n",
    "    # read in zip code data\n",
    "    usa_zip = gpd.read_file('data/raw/public/Pre-Processing/cb_2018_us_zcta510_500k.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only Illinois\n",
    "ill_zip = usa_zip.loc[(usa_zip['GEOID10'] >= '60002') & (usa_zip['GEOID10'] <= '60827')]\n",
    "\n",
    "# Set crs to WGS 84\n",
    "ill_zip = ill_zip.to_crs(epsg=4326)\n",
    "\n",
    "# Check crs\n",
    "print(ill_zip.crs)\n",
    "\n",
    "# Check length\n",
    "print(len(ill_zip))\n",
    "\n",
    "# Rename column names\n",
    "ill_zip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join covid_zip to zip code geographies \n",
    "covid_data = ill_zip.merge(covid_api, how='inner', on='ZCTA5CE10')\n",
    "# Drop extra columns\n",
    "# covid_zip_geo = covid_zip_geo.drop(covid_zip_geo.columns[5:10], axis=1)\n",
    "print(len(covid_data))\n",
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export Final Shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths\n",
    "covid_fp = 'data/raw/public/Pre-Processing/covid_pre-processed.shp'\n",
    "atrisk_fp = 'data/raw/public/Pre-Processing/atrisk_pre-processed.shp'\n",
    "\n",
    "# Export\n",
    "covid_data.to_file(covid_fp)\n",
    "atrisk_data.to_file(atrisk_fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
